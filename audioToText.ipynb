{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c05f0e",
   "metadata": {},
   "source": [
    "# create a notebook for audio to text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984eaaa",
   "metadata": {},
   "source": [
    "The first step is to create an interface for uploading files. For this, we’ll use ipywidgets, a Python library that provides interactive UI components beyond plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a library that has sliders, dropdowns, checkboxes, text boxes, and file upload buttons\n",
    "import ipywidgets as widgets\n",
    "# os is used for working with files, directories, and environment variables.\n",
    "import os\n",
    "# this is to show more interesting outputs than just plain text\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = widgets.FileUpload(accept='.mp3,.wav', multiple=True)\n",
    "display(uploader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8289b19",
   "metadata": {},
   "source": [
    "The next step is to save the uploaded files into a local folder within our project so they can be accessed whenever needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83098bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_uploaded_mp3s(uploader, dest_dir=\"uploads\"):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    saved_paths = []\n",
    "\n",
    "    for file_info in uploader.value:\n",
    "        filename = file_info[\"name\"]\n",
    "        content = file_info[\"content\"] # the contect is not in bytes, it is in memoryview \n",
    "        # memoryview is a view of the original data, so\n",
    "        # we need to convert it to bytes before saving it to a file\n",
    "        if isinstance(content, memoryview):\n",
    "            content = content.tobytes()\n",
    "\n",
    "        out_path = os.path.join(dest_dir, filename)\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        print(\"Saved:\", out_path)\n",
    "        saved_paths.append(out_path)\n",
    "\n",
    "    return saved_paths\n",
    "\n",
    "paths = save_uploaded_mp3s(uploader)\n",
    "print(paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0f8d3",
   "metadata": {},
   "source": [
    "Now that our audio files are uploaded and saved, the next step is to transcribe them into text. We’ll use the Transformers library, which provides a simple way to load and run pretrained models like OpenAI’s Whisper for speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initializing transcriber\n",
    "# Using the small model for faster processing; you can choose other models if needed\n",
    "#we want to use chunking and overlapping to handle long audio files (because the model has a limit on input length of 30s)\n",
    "# .mp3 and .wav and .flac files are supported if you want to use other formats, you need to convert them to one of these formats first\n",
    "# and change the first cell to accept those formats\n",
    "\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-small\",\n",
    "    chunk_length_s=30,   # 30s chunks\n",
    "    stride_length_s=5    # 5s overlap\n",
    ")\n",
    "# Function to transcribe audio files and save them as text files next to the audio files\n",
    "def transcribe_and_save(paths):\n",
    "    for audio_path in paths:\n",
    "        # Transcribe the audio file\n",
    "        result = transcriber(audio_path)\n",
    "        transcription = result[\"text\"]\n",
    "\n",
    "        # Create a text file path by replacing the audio file extension with .txt\n",
    "        base, _ = os.path.splitext(audio_path)\n",
    "        text_file_path = f\"{base}.txt\"\n",
    "\n",
    "        # Save the transcription to the text file\n",
    "        with open(text_file_path, \"w\") as text_file:\n",
    "            text_file.write(transcription)\n",
    "\n",
    "transcribe_and_save(paths)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis477",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
